import streamlit as st
import requests
import pandas as pd
from datetime import datetime
from collections import Counter

# --- CONFIGURATION ---
API_BASE = "https://lotto.api.rayriffy.com/lotto"
API_LATEST = "https://lotto.api.rayriffy.com/latest"

st.set_page_config(
    page_title="Satayu Ultimate Engine",
    page_icon="üß¨",
    layout="centered"
)

# --- ENGINE: REAL-TIME MINER ---
def get_target_date():
    """Auto-detects the next draw date based on today."""
    now = datetime.now()
    
    # Logic: ‡∏ñ‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 16 ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πá‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏á‡∏ß‡∏î‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    if now.day <= 16:
        day = 17 if now.month == 1 else 16  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 1 ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 17 (‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏π)
        return datetime(now.year, now.month, day)
    else:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏¢‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 16 ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πá‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏á‡∏ß‡∏î‡∏ï‡πâ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
        m = now.month + 1 if now.month < 12 else 1
        y = now.year + 1 if now.month == 12 else now.year
        return datetime(y, m, 1)

def mine_historical_data(target_month, target_day):
    """
    MINING: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 10 ‡∏õ‡∏µ ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô 17 ‡∏°.‡∏Ñ.)
    """
    history = []
    current_year = datetime.now().year
    
    # Progress Bar UI
    progress_text = f"üì° Mining Data: ‡πÄ‡∏à‡∏≤‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏≤‡∏ú‡∏• {target_day}/{target_month} ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 10 ‡∏õ‡∏µ..."
    my_bar = st.progress(0, text=progress_text)
    
    years_range = range(current_year - 10, current_year)
    total_steps = len(years_range)
    
    for i, year in enumerate(years_range):
        # Update UI
        my_bar.progress(int((i / total_steps) * 100))
        
        # ‡∏¢‡∏¥‡∏á Request ‡πÑ‡∏õ‡∏ó‡∏µ‡πà API
        url = f"{API_BASE}/{year}-{target_month:02d}-{target_day:02d}"
        try:
            r = requests.get(url, timeout=2)
            if r.status_code == 200:
                data = r.json()
                if 'response' in data and 'runningNumbers' in data['response']:
                    # ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ó‡πâ‡∏≤‡∏¢ 2 ‡∏ï‡∏±‡∏ß
                    num = data['response']['runningNumbers'][0]['number'][0]
                    history.append({"Year": year, "Number": num})
        except:
            continue  # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏µ‡πÑ‡∏´‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏ß‡∏¢‡∏á‡∏î) ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°
            
    my_bar.empty()
    return history

def get_latest_draw_penalty():
    """‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏ó‡∏≥ Penalty)"""
    try:
        r = requests.get(API_LATEST, timeout=2)
        data = r.json()
        return data['response']['runningNumbers'][0]['number'][0]
    except:
        return None

    @st.cache_data(ttl=CACHE_TTL, show_spinner=False)
    def fetch_latest_draw(_self):
        """Fetches data from GLO API with caching to optimize performance."""
        try:
            response = requests.get(API_ENDPOINT, timeout=8)
            if response.status_code != 200:
                _self.api_failures += 1
                return {"date": "Unknown", "number": "N/A", "status": "Offline"}
                
            data = response.json()
            raw_date = data['response']['date']
            result_2d = data['response']['runningNumbers'][0]['number'][0]
            
            # Try parsing multiple date formats
            dt = None
            for fmt in ["%d %B %Y", "%d %b %Y"]:
                try:
                    dt = datetime.strptime(raw_date, fmt)
                    break
                except ValueError:
                    continue
            
            if not dt:
                return {"date": raw_date, "number": result_2d, "status": "Online"}
            
            fmt_date = dt.strftime("%d-%m-%Y")
            
            # Update history if new
            if not any(d['date'] == fmt_date for d in _self.history):
                _self.history.insert(0, {"date": fmt_date, "number": result_2d})
                try:
                    with open(DB_FILE, 'w', encoding='utf-8') as f:
                        json.dump(_self.history, f, indent=2)
                except IOError:
                    pass
            
            return {
                "date": raw_date,
                "number": result_2d,
                "status": "Online"
            }
        except Exception as e:
            _self.api_failures += 1
            return {"date": "Error", "number": "N/A", "status": "Offline"}

    def get_next_draw_context(self) -> Tuple[datetime, List[str]]:
        """
        Calculates the next draw date and cultural bias numbers.
        Handles Thai GLO special dates (Teacher's Day, Labour Day).
        """
        today = datetime.now()
        year, month = today.year, today.month
        
        # Determine next draw date
        if today.day > 16:
            month += 1
            if month > 12:
                month = 1
                year += 1
            day = 1
        else:
            day = 16
            
        # Apply holiday exceptions
        if month == 1 and day == 16:
            day = 17  # Teacher's Day shift
        elif month == 5 and day == 1:
            day = 2   # Labour Day shift
            
        next_date = datetime(year, month, day)
        
        # Build cultural bias set
        bias_nums = []
        
        if month == 1 and day == 17:
            bias_nums.extend(["16", "17", "61", "95", "97"])
        elif month == 5 and day == 2:
            bias_nums.extend(["01", "02", "05"])
            
        # Year-based numbers
        year_str = str(year)[-2:]
        bias_nums.extend([year_str, "96"])
        
        return next_date, list(set(bias_nums))

    def run_advanced_algorithm(self, target_date: datetime, cultural_bias: List[str]) -> List[Tuple[str, int, List[str]]]:
        """
        Advanced multi-factor scoring algorithm.
        Combines cultural patterns, seasonal statistics, and recent trends.
        """
        target_month = str(target_date.month).zfill(2)
        
        scores = Counter()
        evidence = defaultdict(list)
        
        # Factor 1: Cultural/Event-based scoring (Weight: 5)
        for num in cultural_bias:
            scores[num] += self.weights['CULTURE']
            evidence[num].append("Cultural Pattern")
        
        # Factor 2: Seasonal analysis - same month across years (Weight: 3)
        seasonal_nums = [d['number'] for d in self.history 
                        if d['date'].split('-')[1] == target_month]
        
        for num in seasonal_nums:
            scores[num] += self.weights['SEASONAL']
            evidence[num].append("Seasonal Match")
        
        # Factor 3: Recent trend - last 20 draws (Weight: 1)
        if len(self.history) >= 20:
            recent_nums = [d['number'] for d in self.history[:20]]
        else:
            recent_nums = [d['number'] for d in self.history]
            
        for num in recent_nums:
            scores[num] += self.weights['RECENT']
            evidence[num].append("Recent Trend")
        
        # Factor 4: Anti-repeat penalty
        if self.history:
            latest = self.history[0]['number']
            if latest in scores:
                scores[latest] += self.weights['PENALTY']
                evidence[latest].append("‚ö†Ô∏è Repeat Risk")
        
        # Sort and format results
        ranked = scores.most_common(5)
        results = []
        for num, score in ranked:
            results.append((num, score, evidence[num]))
        
        return results

# --- UI IMPLEMENTATION ---

st.title("üß¨ Satayu Ultimate Engine")
st.caption("Real-Time Data Mining + Thai Cultural Logic Intersection")

# ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (Target)
target = get_target_date()
st.info(f"üéØ Target Draw Detected: **{target.strftime('%d %B %Y')}** (‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)")

if st.button("üöÄ Run Live Analysis", type="primary"):
    
    # --- STEP 1: MINING (‡∏Ç‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á) ---
    with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Server ‡∏Å‡∏≠‡∏á‡∏™‡∏•‡∏≤‡∏Å‡∏Ø..."):
        raw_history = mine_historical_data(target.month, target.day)
        penalty_num = get_latest_draw_penalty()
    
    if not raw_history:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Check Internet Connection)")
        st.stop()

    # ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (Evidence)
    st.subheader("1. Hard Evidence (‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤)")
    df = pd.DataFrame(raw_history)
    st.dataframe(df.set_index("Year").T, use_container_width=True)

    # --- STEP 2: LOGIC PROCESSING ---
    
    # A. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (Statistical Analysis)
    numbers = [x['Number'] for x in raw_history]
    all_digits = "".join(numbers)
    # ‡∏´‡∏≤ "‡πÄ‡∏•‡∏Ç‡∏ß‡∏¥‡πà‡∏á" ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ
    top_digit = Counter(all_digits).most_common(1)[0][0]
    
    # B. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Cultural Bias)
    bias_set = set()
    # 1. ‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    bias_set.add(f"{target.day:02d}")       
    bias_set.add(f"{target.day-1:02d}")     
    # 2. ‡πÄ‡∏•‡∏Ç‡∏õ‡∏µ (‡∏û.‡∏®./‡∏Ñ.‡∏®.)
    bias_set.add(str(target.year)[-2:])     # 26
    bias_set.add(str(target.year+543)[-2:]) # 69
    # 3. ‡πÄ‡∏•‡∏Ç Event (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏π)
    if target.month == 1 and target.day == 17:
        bias_set.update(["61", "95", "19", "79"])

    # --- STEP 3: INTERSECTION SCORING ---
    scores = {}
    reasons = {}

    # Logic 1: ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏•‡∏Ç‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (+5)
    for n in bias_set:
        scores[n] = scores.get(n, 0) + 5
        reasons[n] = ["Cultural Bias"]

    # Logic 2: ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏Ç‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á "‡πÄ‡∏•‡∏Ç‡∏ß‡∏¥‡πà‡∏á" ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (+3)
    # (‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏Ç 9 ‡∏°‡∏≤‡∏ö‡πà‡∏≠‡∏¢ ‡πÄ‡∏•‡∏Ç 97, 19 ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°)
    for n in scores:
        if top_digit in n:
            scores[n] += 3
            reasons[n].append(f"Stat Match '{top_digit}'")

    # Logic 3: ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏Ç‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏≠‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå (+5)
    for hist in raw_history:
        n = hist['Number']
        scores[n] = scores.get(n, 0) + 5
        if n not in reasons: reasons[n] = []
        reasons[n].append("History Repeat")

    # Logic 4: PENALTY (-20) **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å**
    # ‡∏´‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏≠‡∏≠‡∏Å‡∏ã‡πâ‡∏≥‡∏¢‡∏≤‡∏Å)
    if penalty_num and penalty_num in scores:
        scores[penalty_num] -= 20
        reasons[penalty_num].append("‚õî Penalty (Recent)")

    # --- STEP 4: RESULT DISPLAY ---
    st.subheader("2. Final Optimized Prediction")
    
    # ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
    top_picks = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]
    
    # Winner Card
    winner = top_picks[0]
    st.markdown(f"""
    <div style="background:linear-gradient(45deg, #FF4B4B, #FF9068); padding:20px; border-radius:15px; text-align:center; color:white; margin-bottom:20px; box-shadow: 0 4px 15px rgba(255, 75, 75, 0.4);">
        <div style="font-size:1rem; opacity:0.9;">‚ú® Best Intersection Match</div>
        <div style="font-size:4rem; font-weight:800; letter-spacing: 2px;">{winner[0]}</div>
        <div style="background:rgba(255,255,255,0.2); display:inline-block; padding:5px 15px; border-radius:20px; margin-top:5px;">
            Confidence Score: {winner[1]}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Detail Table
    table_data = []
    for num, score in top_picks:
        table_data.append({
            "Number": num,
            "Score": score,
            "Logic Sources": ", ".join(reasons.get(num, []))
        })
        
    st.table(pd.DataFrame(table_data))
    
    st.success(f"üí° **Insight:** ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏Ç **{top_digit}** ‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏á‡∏ß‡∏î {target.day}/{target.month} ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 10 ‡∏õ‡∏µ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∂‡∏á‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ {top_digit} ‡∏ú‡∏™‡∏°‡∏≠‡∏¢‡∏π‡πà")
